Slide 9.4

Ora, il contesto in cui ci troviamo a lavorare è quello della multiprogrammazione, cioè il sistema di elaborazione non è limitata, un solo task, un solo processo, ma può avere più processi attivi oltre al kernel sistema operativo residente. Questo significa che quando un programma viene mandato in esecuzione, un programma viene mandato in esecuzione mediante un comando su una linea di comandi, piuttosto che non un doppio click su un'icona, dipende dall'interfaccia con l'utente che è prevista per il sistema, ma un programma viene mandato in esecuzione e spesso vengono mandati in esecuzione più programmi. Immaginate, provate a pensare alle app che sono attive su un tablet o su uno smartphone, provate a pensare a quanti programmi in parallelo possono essere attivi su un qualunque pc in un momento della vostra attività. Un programma viene mandato in esecuzione di fatto al doppio click, all'invio dopo aver scritto il nome del programma, portando l'eseguibile dal disco in memoria.

Attenzione, in memoria qui si intende memoria volatile, memoria RAM e penso che ognuno di voi abbia tutto sommato già una certa sensibilità nel differenziare, nel capire qual è la differenza tra la memoria di massa, I dischi, I file e la memoria RAM, memoria cosiddetta volatile, quella che perde informazione quando si spegne il computer. La differenza tra memoria di massa e memoria RAM può essere analizzata in vari modi. Di fatto dal punto di vista della cpu la vera ragione per cui ci sono questi due livelli è che la memoria RAM permette di lavorare a una certa velocità, il disco è tutto sommato troppo lento. Difatti il secondo punto che vedete qua dice che la CPU come vere memorie su cui lavorare a disposizione I registri che sono dentro alla cpu ma sono pochi e la memoria RAM che è fuori dalla cpu ma che dimensioni ragionevoli tanto per intenderci sapete che le memorie RAM attuali possono avere dimensioni grosso modo di gigabyte, decine di gigabyte e anche centinaia di gigabyte a seconda dei sistemi operativi dei sistemi di elaborazione utilizzati dovreste anche sapere che tipicamente I registri vanno da alcune decine, può anche darsi qualche centinaio anche se è abbastanza raro, ma comunque I registri che sono interni alla cpu hanno dimensioni molto inferiori a quelle delle Memorie RAM per accedere alla memoria un elaboratore, un microprocessore bisogno di utilizzare indirizzi e dati.

Ci saranno l'address BUS, il data BUS e il control BUS che sono I canali hardware usati per la comunicazione tra microprocessore e memoria e mentre l'accesso ai registri è un accesso rapido l'accesso che potrebbe essere pensato all'interno di un colpo di clock, e vi faccio notare che I GHz sono di fatto l'inverso di nanosecondi, quindi sono velocità molto elevate, L'accesso alla memoria RAM spesso e volentieri altre tempistiche. Tra l'altro, quando si pensa di acquistare, utilizzare, dimensionare un sistema di elaborazione, consiglio di verificare I tempi sia della cpu, la frequenza della cpu che della memoria RAM. Voi tutti dovreste anche avere noto il concetto di cache che, detto in termini estremamente sintetici, è una memoria intermedia che cerca di avere le velocità o velocità, tempi di accesso molto più vicini al microprocessore e dimensioni tutto sommato non così lontane dalla RAM o meglio, dimensioni intermedie tra la RAM e I registri del microprocessore. Un ultimo aspetto che vedremo tra un altro è quello della protezione. In questo contesto si intende semplicemente che sia in modo volontario che in modo non volontario, quindi non necessariamente assumendo che si tratti di hacker piuttosto che non di processi malevoli, dicevo che si affronta il problema di fare in modo che un processo non possa interferire sulla memoria di un altro processo e peggio ancora sulla memoria del sistema.

Dico questo perché I sistemi operativi di qualche decennio fa dei primi PC, parlo di MS-DOS per esempio, non avevano queste caratteristiche. 

Slide 9.5

Ora, nel farvi notare che alcune delle slide che qui vedete si distinguono chiaramente dalle altre per non essere originali del Sylberschartz, queste ad esempio sono state estratte dal Tanembaum e sono un tentativo di integrare informazioni aggiuntive che dovrebbero servire a spiegare meglio quello che è comunque già detto nel Silverschads. Allora questo questa figura vi dovrebbe permettere di rivedere qual è il meccanismo di creazione e di un programma eseguibile. Quello che vorrei che voi notaste è che qui si vedono le azioni del compilatore e del link nel produrre a partire da file sorgenti ad esempio file c ne vedete lì tre main, help e other. C vedete anche due.

H che sono file header e compito del compilatore che si distingue tipicamente almeno in due fasi il preprocessore c e il compilatore vero e proprio quello di generare per ogni sorgente c un file oggetto qui la terminologia e le estensioni sono del mondo unix quindi vedete dei file .o. I tre file oggetto poi vengono messi insieme per creare un unico eseguibile che a meno di usare altre opzioni si chiama per default appunto out in Unix normalmente si danno altri nomi. Il link oltre a unire e mettere insieme, poi vedremo qualche dettaglio in più, I file oggetto unisce cioè aggiunge all'eseguibile le possibilità di chiamare funzioni di libreria Vedete qui libc. A sta ad indicare un archivio di funzione di libreria C. 

Slide 9.6

Bene, in questo contesto un eseguibile che è stato generato in questo modo verrà utilizzato per far partire, per caricare avviare un processo e in un sistema con multiprogrammazione quello che succede è che nella RAM ad un certo momento saranno presenti più processi insieme al sistema operativo o meglio al kernel.

Vi faccio notare che in questo in questa figura come in altre che vedremo si rappresenta l'indirizzo zero in basso e l'indirizzo massimo in alto. Non è l'unica convenzione usata. Talvolta o altre volte vedrete lo zero in alto e l'indirizzo massimo in basso. Quindi l'importante è imparare a orientarsi e a capire di cosa si sta parlando. Qui l'esempio proposto vi fa vedere come nel momento in cui in un sistema in azione in operazione fossero presenti ad esempio il sistema operativo nella parte grigia in alto a certi indirizzi e tre processi indicati lì con process.

Una parte della RAM tra l'altro libera ciò che bisogna garantire in termini di protezione è fare in modo che il generico processo, e qui parliamo ad esempio del processo che sta in mezzo, non esca dai suoi bordi cioè acceda solo alla RAM che gli è riservata e non vada né a leggere ma peggio ancora a scrivere, a sovrascrivere RAM che non gli compete. Ad esempio il sistema operativo o la RAM allocata utilizzata da altri processi. Per fare questo di fatto mentre un processo è in esecuzione è importante che ci siano e sono nella cpu due registri che stanno ad indicare l'indirizzo di base e il limite. Ora che l'indirizzo di base sia l'indirizzo completo di partenza e il limite sia semplicemente quanto bisogna aggiungere a questo indirizzo oppure sia l'indirizzo finale questo può dipendere dal contesto del microprocessore. Qui quello che vedete è che ad esempio questo processo lavora e riservato alla RAM dall'indirizzo trecentomila quaranta a quattrocentoventimila novecentoquaranta possiamo dire che base è trecentomila quaranta e limit è quanto bisogna aggiungere a trecentomila quaranta per raggiungere quattrocentoventimila novecentoquaranta.

Slide 9.7

Vediamo ora un altro aspetto del problema di allocare e assegnare più processi a zone diverse della memoria. In questa illustrazione vedete come due processi A e B entrambi illustrati in maniera molto sintetica. Possiamo vedere che hanno entrambi l'indirizzo zero con una Jump, notate anche qui gli indirizzi vanno dal basso in alto. Entrambi hanno una jump, il processo A una jump a ventiquattro dove c'è una prima istruzione di move, il processo B è una jump a ventotto dove c'è una prima istruzione di compere. Come vedete entrambi I processi credono di lavorare a partire dall'indirizzo zero.

Nel momento in cui questi due processi fossero piazzati in memoria RAM come nella parte destra della figura, sarebbe possibile ad esempio avere il processo, il primo dei due processi, in realtà non sono A e B ma A e B sono la numerazione delle figure, ma comunque il primo dei processi, quello più scuro, all'indirizzo zero e questo primo processo a partire dall'indirizzo zero vedrebbe gli indirizzi corretti. Jump ventiquattro significa effettivamente andare alle istruzioni all'indirizzo ventiquattro, eseguire Move e Ad. Se il processo, il secondo processo, quello che ho chiamato B fosse piazzato in sequenza in memoria a partire da quell'indirizzo sedicimila trecentottantaquattro voi vedreste che quella Jump ventotto non molto senso perché Jump ventotto invece di mandare alla comper manderebbe alla AD del precedente processo, tra l'altro probabilmente protetta. Cioè quello che possiamo notare è come piazzare, collocare un processo ad indirizzi arbitrari nella RAM non è indolore. 

Slide 9.8

Quello che si può tentare di fare è sfruttare quelli che prima abbiamo visto registri solo di protezione, il base register e il limite register, oltre che per indicare da dove inizia e dove finisce in ram la sezione dedicata a un processo, ma anche usarli sostanzialmente per rilocare per ricalcolare gli indirizzi effettivi ad esempio intendendo quel jump ventotto come jump all'indirizzo ventotto aggiunto al base register.

Vi faccio notare come in questa figura il limite register sia effettivamente l'indirizzo sembrerebbe finale del processo in corso anche se il limite Register è l'indirizzo finale partendo da zero. Quello che notate è che sedicimila trecentottantaquattro più sedicimila trecentottantaquattro il limite Register fa effettivamente trentaduemila settecentosessantaquattro. Bene, questo è il problema. 

Slide 9.9

Ho più in dettaglio il concetto di rilocazione e introduciamo il termine Binding che significa collegare, legare, connettere, associare. Cioè bind significa associare un indirizzo effettivo a un indirizzo simbolico, logico o comunque connettere due indirizzi facendo in modo che si corrispondano.

Il problema è che se un programma che viene portato un eseguibile che viene portato da disco in memoria non un supporto cioè un meccanismo di gestione automatizzata di associazione tra indirizzi o di equivalenza tra indirizzi non può che richiedere di conoscere già a che indirizzo funzionerà, che indirizzo sarà caricato. La cosa più semplice è pensare che un programma debba iniziare l'indirizzo zero. Nei sistemi più semplici questo è l'unico sistema, indirizzi di fatto assoluti. Il che però implica che in un sistema un programma, un processo utente non possa che partire dall'indirizzo zero. Questo può essere un vincolo.

Si potrebbe cambiare invece che all'indirizzo zero dire al compilatore questo programma per favore fammelo iniziare un altro indirizzo. Però sono schemi fissi che su pc non vanno molto bene, su sistemi di elaborazione complessi non vanno molto bene, possono andare bene in certi sistemi ad esempio embedded piuttosto semplici in cui gira un solo programma o girano pochissimi programmi e gli schemi sono relativamente fissi. Ora diamo un'occhiata a questo concetto di Binding e vediamo che Binding di fatto significa mettere in corrispondenza, completare, dire a quale indirizzo vero corrisponde quello che era un indirizzo non finto ma ancora provvisorio. Qui vi si dice che il codice sorgente o nel codice sorgente gli indirizzi sono di fatto tutti simbolici nel senso che in un programma voi non scriverete mai in un ciclo for, un while o una chiamata di funzione l'indirizzo a cui bisogna ritornare piuttosto che non la funzione dove sta la funzione da chiamare, ma si danno dei nomi e quindi gli indirizzi lì sono simbolici. Una volta che il compilatore traduce un programma in codice Assemblr codice macchina metterà degli indirizzi.

Allora se il compilatore mette degli indirizzi rilocabili significa che invece di scrivere degli indirizzi definitivi scriverà ad esempio quattordici byte dall'inizio di questo modulo. È ovvio che questo non è ancora un indirizzo ma va ancora completato il completamento potrà essere fatto rispetto a un codice oggetto o dal linker o dal loader dipende da quali sono gli schemi per ora lasciamolo vago se è fatto dall'Inker significa che nell'eseguibile ci saranno già gli indirizzi finali e quindi l'unico problema è stato quello di mettere insieme le cose non è ancora uno schema di rilocazione non così forte ma comunque già dei vantaggi. Se lo fa il loader vuol dire che mentre il programma viene caricato in memoria allora lì si decidono gli indirizzi e allora uno dei due completerà e invece di scrivere quattordici byte dopo scriverà ad esempio settantaquattromila quattordici. Di fatto ogni processo ogni operazione di bind mappa un indirizzo in un altro diciamo un indirizzo provvisorio incompleto ancora da definire in un indirizzo definito. 

Slide 9.10

Nel momento in cui si parla a questo punto di istruzioni e di dati da associare a una memoria da caricare in RAM possiamo identificare tre possibili fasi in cui questa operazione di Binding concretamente avviene.

Le tre fasi sono: la fase cosiddetta di compilazione e con compilazione potremmo intendere l'unione sia di compilazione che link con compilazione qui possiamo intendere generazione dell'eseguibile poi la fase di load, caricamento dell'eseguibile in memoria e poi la fase di esecuzione ora mentre la prima è abbastanza facilmente comprensibile dire che il Binding viene fatto in Compile Time significa che bisogna conoscere a quale indirizzo sarà eseguito un certo programma e nell'eseguibile si mettono indirizzi assoluti. Quindi questa è un'operazione semplice in sistemi relativamente semplici si può usare questa strategia. Dire invece che il programma o meglio il Binding viene fatto in fase di load significa che innanzitutto il codice eseguibile deve essere rilocabile Che vuol dire che mentre viene collocato in RAM, l'eseguibile viene completato e si mettono gli indirizzi giusti perché si sa dove vengono collocate le varie parti del programma. L'esecuzione allora potrebbe a prima vista sembrare un po' complicato distinguere tra load esecuzione nel senso che il load è la parte iniziale dell'esecuzione e l'esecuzione significa eseguire un programma di cui è stato appena fatto load. La sottile differenza che c'è tra load ed esecuzione sta nel fatto che Binding in esecuzione non significa Binding fatto una tantum all'inizio dell'esecuzione della prima istruzione, ma significa Binding differito fino all'esecuzione di un certo modulo, di una certa funzione.

Cioè in parole povere supponiamo che un programma sia caricato in memoria load. Binding non ancora fatto nel momento in cui si arriverà a eseguire una certa parte del programma allora lì si dovrà fare in modo che gli indirizzi siano associati effettivamente agli indirizzi veri che vanno utilizzati cioè è una forma ancora più forte supponiamo che un programma chiami la funzione A e la funzione B si farà binding sulla funzione A solo quando viene chiamato o quando verrà chiamata. Vedremo esempi di questo più avanti. 

Slide 9.11

Quindi lo schema potrebbe essere quello che vedete qui in figura. In sostanza voi vedete il bind in tempo di compilazione, di load e di esecuzione nelle varie parti vedete che sostanzialmente avete il compilatore che traduce da programma sorgente a programma oggetto il linker si accontenta di generare un modulo eseguibile a partire da moduli oggetto ed eventuali librerie e via dicendo Il Binding in compail time significa che nell'eseguibile vanno a finire degli indirizzi assoluti.

Il Binding in fase di load significa che sia il linker sia il loader debbono collaborare il linker nel produrre un eseguibile che possa essere di fatto rilocato in fase di caricamento in memoria, cioè che possa essere non solo preso e copiato così com'è, ma mentre si copia l'eseguibile in RAM si debbono mettere a posto gli indirizzi. Ovviamente una volta saputo dove questo programma viene caricato in RAM. La fase di Binding in fase di esecuzione e l'ultima che viene visualizzata in basso significa in pratica che in modo più dinamico ogni pezzo del programma che viene attivato e solo se viene attivato sarà rilocato in modo opportuno. 

Slide 9.12

Questo di fatto se vogliamo arrivare a gestire la rilocazione in fase di esecuzione ci spinge o è stato risolto in qualche modo arrivando alla nozione di indirizzo logico e indirizzo fisico cioè l'unica vera soluzione per permettere di differire quanto più possibile l'associazione di un indirizzo mediante Binding all'indirizzo vero, cioè all'indirizzo in memoria in cui sta un dato o un'istruzione, è quello di far sì che in fase di esecuzione ci sia, mi permetto di dire al volo gestito direttamente dall'hardware, ci sia una traduzione tra quello che è un indirizzo logico che è ciò che vuol vedere il programma e un indirizzo fisico che è quello che andrebbe usato dalla cpu per accedere alla ram.

Quindi il concetto di indirizzo logico è quello di indirizzo che viene, attenzione generato dalla cpu, vuol dire quello che è scritto dentro al codice Assemblr, al codice eseguibile. Questo indirizzo è un numero ma non è ancora il numero vero che dovrà andare a finire sul ladress BUS. Questo si chiama invece indirizzo fisico L'indirizzo fisico è quello che viene visto dalla memoria. Provo a ridirlo: la cpu emette un indirizzo logico e la memoria riceve un indirizzo fisico. Vuol dire che da qualche parte tra la cpu e la memoria nel passaggio sull'adleress bus c'è un meccanismo di traduzione e questo meccanismo di traduzione si chiama traduzione da indirizzo logico a indirizzo fisico ed è sostanzialmente l'oggetto del capitolo nove e del capitolo dieci del Silvershads e del resto di questa lezione e della prossima anzi delle prossime probabilmente

Slide 9.13

quindi la soluzione per fare in modo che si possa fare Binding in esecuzione è far sì che questo Binding sia fatto in modo automatico e sia di fatto realizzato in modo automatico dalla cosiddetta memory management unit che è un pezzo di hardware cioè qualche cosa che sta a bordo della cpu che è stato pensato progettato realizzato dal progettista della cpu o dai progettisti della cpu ma quello che sono solito dire agli studenti informatici è il lavoro di un ingegnere elettronico cioè di qualcuno che progettato l'hardware che serve a tradurre l'indirizzo logico in indirizzo fisico.

Di questo probabilmente avete già parlato quando avete affrontato problemi di architettura e dei sistemi di elaborazione. Il meccanismo più semplice per realizzare questa Memory Management Unit o la parte della Memory Management Unit che fa traduzione da indirizzo logico fisico è quello di usare il cosiddetto Relocation Register. Il relocation register non è niente meno che quello che prima chiamavamo base register e che di fatto verrà sommato in modo automatico a livello hardware all'indirizzo logico. Il valore che cenere location register ad ogni accesso in memoria sarà sommato tramite un addizionatore che sta dentro al memory management unit all'indirizzo logico quello che crede di usare il programma ma non è l'indirizzo che va a finire tramite l'address bus alla ram. Quindi se nel programma che è già diventato codice macchina prima codice assemblea del codice macchina se nel programma c'è un indirizzo logico questo diventerà indirizzo fisico dopo aver sommato il relocation register.

Slide 9.14 - 15

In pratica lo schema è questo: la cpu internamente produce l'indirizzo trecentoquarantasei, la memory management unit non facciamoci confondere la memory management unit è dentro alla cpu la memory management unit ad esempio somma questo trecentoquarantasei al quattordicimila che sta nel re location register e genera un indirizzo fisico quattordicimila trecentoquarantasei che è l'indirizzo vero che arriva alla memoria RAM. 

Slide 9.16

Ora vediamo come queste azioni di Binding e di traduzione da indirizzo logico a indirizzo fisico fatte automaticamente possono essere utilizzate per realizzare vari schemi di caricamento ed esecuzione del programma che possiamo definire con Dynamic loading e successivamente vado avanti al prossimo lucido poi torno indietro Dynamic linking. Ora cerchiamo di capire perché questi due concetti, Dynamic loading e linking, spesso sono confusi o comunque sono usati in modo quasi interscambiabile anche se in realtà non significano la stessa cosa. In realtà è possibile che un programma non abbia Dynamic loading e neppure Dynamic linking. È possibile che ne abbia solo uno dei due o li abbia entrambi Tenete presente che Dynamic loading significa caricamento dinamico vuol dire carico in memoria in modo dinamico cioè un po' alla volta quando serve.

Il concetto di dynamic loading significa che un programma intero può essere caricato in memoria a pezzettini uno alla volta leggete questo secondo punto che dice una routine, una funzione ad esempio, una funzione C non è caricata finché non è chiamata Dynamic loading significa di fatto questo ci può essere un programma anche grande che al suo interno dieci funzioni supponete che è un'esecuzione di quel programma di queste dieci funzioni ne vengano usate solo due esempio un programma di gestione dell'archivio anagrafico di un comune, operatrice, operatore a terminale in una certa giornata farà soltanto carte d'identità e ad esempio certificati di residenza nel programma ci sono funzioni per fare altre otto possibili certificazioni o altro in effetti sarebbe stato inutile caricare in memoria le funzioni delle altre otto certificazioni, sarebbe stato sufficiente caricare in memoria RAM I programmi per le carte d'identità e I certificati di residenza. Si chiama quindi loading dinamico caricamento dinamico l'idea di portare in memoria solo ciò che serve. Questo un unico vero obiettivo risparmiare spazio in memoria. Per fare questo è ovvio che il Binding deve essere fatto in modo dinamico e deve essere fatto in fase di esecuzione e ogni funzione ogni modulo sarà caricato e collegato agli indirizzi veri soltanto quando serve qui tuttavia vi si dice che non c'è un supporto vero dal sistema operativo in realtà questa frase è parzialmente vera, parzia parzialmente falsa ma l'idea è questo il concetto di Binding scusate il concetto di Dynamic loading significa il programmatore e non il sistema operativo a disposizione delle funzioni di fatto per non dico allocare dinamicamente un vettore ma caricare dinamicamente una funzione.

E' come se, torno all'esempio precedente, chi scritto il programma di gestione dello sportello anagrafico faccia questo if se il comando è carta d'identità se la funzione carta d'identità è già stata caricata vai avanti e chiamala. Se no carica questa funzione fai load e poi eseguila. Quindi è un problema in qualche modo gestito dal programmatore che vedrà e scriverà delle istruzioni esplicite di caricamento load di funzioni. 

Slide 9.17

Si chiama invece Dynamic linking un altro tipo di problema o un altro tipo di concetto che è contrapposto al cosiddetto static linking. Tenete conto che link mentre load significa carica in memoria, link significa collega link significa collegare pezzi di un programma decidendo gli indirizzi e il linking è l'operazione fatta dal linked ed è sostanzialmente quella di decidere specialmente per quanto riguarda le funzioni le sabrutin le il I vari moduli di un programma ma potrebbe anche essere per strutture dati decidere gli indirizzi che vengono utilizzati da un modulo e che sono di oggetti non interni a quel modulo ma in un altro modulo a cosa corrispondono.

Supponete, per quelli di voi che ad esempio hanno fatto con con me algoritmi al secondo anno, supponete di avere un programma main che chiama una funzione che è scritta in un altro modulo, in un altro punto c. Questa funzione in main. O o main. Bj se siamo in un contesto Windows. Allora questa funzione oggetto nel file oggetto del main non c'è viene chiamata ma non c'è e di fatto una chiamata una funzione lasciata in sospeso ci sarà un altro file ad esempio supponiamo che la funzione sia sort supponiamo che sia merge.

Questo merge sarà scritto in un altro file merge. C la funzione sarà merge. O quando il linker connette mette insieme main. O e merge. O allora fa questo linking cioè associa all'indirizzo del merge sort chiamato dal main l'indirizzo vero del merge sort presente in merge.

O quindi nell'eseguibile e questo indipendentemente dal fatto che per ora sia un indirizzo rilocabile o meno. Si parla di static linking cioè link statico se il link e il loder al caricamento decidono tutti gli indirizzi rilocabili o meno, ma quando il programma parte gli indirizzi sono tutti già a posto. Si parla invece di Dynamic linking, decisione degli indirizzi non caricamento, su il concetto di assegnare un indirizzo a un'entità tipicamente una funzione solo al momento in cui questa viene eseguita. Questo viene tipicamente fatto mediante un automatismo che è quello del cosiddetto STAB. STAB è un pezzettino che che sostituisce la funzione vera che viene messo nell'eseguibile come se l'eseguibile avesse invece della funzione merge sort due istruzioni che saranno semplicemente di questo tipo la prima volta che passi di qui vai a cercare il merge soft aggancialo e poi questo tab non serve più non voglio entrare nel dettaglio di come funzioni questo tab però l'idea qui non è caricare dinamicamente ma è di assegnare un indirizzo a un indirizzo quello a cui corrisponde un indirizzo ancora aperto ancora non deciso ciò a cui corrisponde solo nel momento dell'esecuzione Ora il fatto che spesso e volentieri il Dynamic loading e il Dynamic linking siano realizzati insieme genera spesso confusione.

E' vero che talvolta Dynamic Link viene proprio usato per funzioni di libreria che sono caricate dinamicamente e l'indirizzo viene riconosciuto e associato alle istruzioni opportune solo nella fase di load. Questo viene fatto per le cosiddette librerie shared esempio il quicksort Qsort del C può essere in una libreria shared condivisa in fase di esecuzione e tutti I programmi potrebbero fare I C che fanno chiamata alla Qsort fanno riferimento alla stessa funzione che per certi versi viene caricata dinamicamente e poi viene anche agganciata linkata dinamicamente